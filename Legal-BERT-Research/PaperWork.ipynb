{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238e906b-875a-4c31-bfc3-903944c44c90",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "    Background and Motivation\n",
    "    The Role of AI in Legal Interpretation\n",
    "    Challenges of Bias in Legal AI Models\n",
    "    Distinction Between Interpretability and Explainability\n",
    "    Objectives and Hypotheses of the Study\n",
    "\n",
    "2. Literature Review\n",
    "\n",
    "    LegalBERT and Its Applications\n",
    "    Bias in Natural Language Processing Models\n",
    "    Understanding Interpretability vs. Explainability\n",
    "        Definitions and Differences\n",
    "        Importance in AI Models\n",
    "    Attention Mechanisms in Deep Learning\n",
    "    Interpretability Methods\n",
    "        Integrated Gradients\n",
    "        Saliency Scores\n",
    "    Explainability Methods\n",
    "        Counterfactual Explanations\n",
    "        Other Explainability Techniques\n",
    "    Previous Work on Bias Detection and Mitigation\n",
    "\n",
    "3. Methodology\n",
    "\n",
    "    Data Collection and Preparation\n",
    "        Sources of Legislative Data\n",
    "        Preprocessing Techniques\n",
    "    Model Fine-Tuning Process\n",
    "        Details of Fine-Tuning LegalBERT\n",
    "        Baseline Models for Comparison\n",
    "    Experimental Design\n",
    "        Prompt Perturbation Strategies\n",
    "        Implementation of Interpretability Methods\n",
    "        Implementation of Explainability Methods\n",
    "    Evaluation Metrics\n",
    "        Measuring Sensitivity and Bias\n",
    "        Statistical Analysis Techniques\n",
    "\n",
    "4. Results\n",
    "\n",
    "    Robustness to Prompt Perturbations\n",
    "        Impact on Model Predictions\n",
    "        Statistical Significance Testing\n",
    "    Analysis of Attention Mechanisms\n",
    "        Findings from Interpretability Methods\n",
    "            Integrated Gradients Results\n",
    "            Saliency Score Patterns\n",
    "        Insights from Explainability Methods\n",
    "            Counterfactual Explanation Findings\n",
    "    Identification of Unintended Biases\n",
    "        Specific Linguistic Features Influencing the Model\n",
    "        Quantification of Bias Effects\n",
    "\n",
    "5. Discussion\n",
    "\n",
    "    Interpretation of Results\n",
    "        Comparing Findings with Null Hypothesis\n",
    "        Implications for Legal Interpretations\n",
    "    Sources of Bias\n",
    "        Data-Driven Biases\n",
    "        Model Architecture Considerations\n",
    "    Effectiveness of Interpretability and Explainability Methods\n",
    "        Complementary Insights Provided\n",
    "    Limitations of the Study\n",
    "        Data Limitations\n",
    "        Methodological Constraints\n",
    "\n",
    "6. Bias Mitigation Techniques\n",
    "\n",
    "    Alignment Strategies\n",
    "        Approaches to Reduce Bias\n",
    "        Implementation Details\n",
    "    Evaluation of Mitigation Efforts\n",
    "        Post-Mitigation Analysis\n",
    "        Effectiveness of Different Techniques\n",
    "    Recommendations for Model Improvement\n",
    "\n",
    "7. Conclusion\n",
    "\n",
    "    Summary of Key Findings\n",
    "    Contributions to the Field\n",
    "    Implications for Future Research and Practice\n",
    "    Final Remarks\n",
    "\n",
    "8. References\n",
    "\n",
    "    Citations of All Sources Used\n",
    "\n",
    "9. Appendices\n",
    "\n",
    "    Supplementary Data\n",
    "        Additional Tables and Figures\n",
    "    Detailed Methodological Procedures\n",
    "    Code and Model Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fde44-0beb-4084-bf6b-52436b7f0d2c",
   "metadata": {},
   "source": [
    "Data Collection:\n",
    "\n",
    "\n",
    "https://www.congress.gov/browse/policyarea/93rd-congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fe820-f23f-4667-9570-44b176c1b9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db8c8cec-e103-4ed8-a3a8-bba00eba8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = '/Users/lennox/Documents/machineLearning/data/policy/93-118OCT28MasterCSV.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for duplicate rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "41f187b7-ddfb-464e-b24a-11c06fb90712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Title', 'Subject'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "df161f45-1b9b-4d3b-8fe7-49e120e968e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9427d1da-d4f0-49d3-bb8f-b50ab3c041da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ecf71ff3-bee8-46bf-ab19-73bfecf019bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific symbols but keep common punctuation\n",
    "df['Title'] = df['Title'].str.replace(r'[^\\w\\s,;:.]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b062ae56-ff8f-465f-aaba-59bcce5a3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping file created as 'category_mapping.csv'\n",
      "                                       Category  Encoded Value\n",
      "0                          Agriculture and Food              0\n",
      "1                                       Animals              1\n",
      "2            Armed Forces and National Security              2\n",
      "3                   Arts, Culture, and Religion              3\n",
      "4   Civil Rights and Liberties, Minority Issues              4\n",
      "5                                      Commerce              5\n",
      "6                                      Congress              6\n",
      "7                     Crime and Law Enforcement              7\n",
      "8                   Economics and PublicFinance              8\n",
      "9                                     Education              9\n",
      "10                         Emergency Management             10\n",
      "11                                       Energy             11\n",
      "12                     Environmental Protection             12\n",
      "13                                     Families             13\n",
      "14                 Finance and Financial Sector             14\n",
      "15      Foreign Trade and International Finance             15\n",
      "16           Government Operations and Politics             16\n",
      "17                                       Health             17\n",
      "18            Housing and Community Development             18\n",
      "19                                  Immigration             19\n",
      "20                        International Affairs             20\n",
      "21                         Labor and Employment             21\n",
      "22                                          Law             22\n",
      "23                             Native Americans             23\n",
      "24           Public Lands and Natural Resources             24\n",
      "25          Science, Technology, Communications             25\n",
      "26                  Social Sciences and History             26\n",
      "27                               Social Welfare             27\n",
      "28                        Sports and Recreation             28\n",
      "29                                     Taxation             29\n",
      "30              Transportation and Public Works             30\n",
      "31                  Water Resources Development             31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the 'category' column\n",
    "le = LabelEncoder()\n",
    "df['category_encoded'] = le.fit_transform(df['Subject'])\n",
    "\n",
    "# Create a dynamic mapping DataFrame\n",
    "mapping_df = pd.DataFrame({\n",
    "    'Category': le.classes_,\n",
    "    'Encoded Value': range(len(le.classes_))\n",
    "})\n",
    "\n",
    "# Save the mapping to a CSV file\n",
    "mapping_df.to_csv('subject_mapping.csv', index=False)\n",
    "\n",
    "print(\"Mapping file created as 'category_mapping.csv'\")\n",
    "print(mapping_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b9952-77a4-4dd6-8f2e-792989ce47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# init wanb for real time train info\n",
    "wandb.init(project=\"legal-bert-classification\", name=\"training-run-1\")\n",
    "\n",
    "# had to buy credit on colab to use T4 gpu\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "texts = df'Title'].astype(str).tolist()\n",
    "labels = df['Subject'].tolist()\n",
    "\n",
    "# encode numeric\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# log to wanb and save model\n",
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "wandb.log({\"label_mapping\": label_mapping})\n",
    "\n",
    "# save label as file\n",
    "with open('label_mapping.json', 'w') as f:\n",
    "    json.dump(label_mapping, f)\n",
    "\n",
    "print(\"Label mapping saved to 'label_mapping.json'\")\n",
    "\n",
    "# save encode to csv\n",
    "labels_df = pd.DataFrame({\n",
    "    'Original Label': labels,\n",
    "    'Encoded Label': encoded_labels\n",
    "})\n",
    "labels_df.to_csv('saved_labels.csv', index=False)\n",
    "print(\"Original and encoded labels saved to 'saved_labels.csv'\")\n",
    "\n",
    "# split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# tokenizer\n",
    "model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "val_encodings = tokenize_function(val_texts)\n",
    "\n",
    "# custom pytorch class to handle encodings\n",
    "class LegislativeDataset(Dataset):\n",
    "\n",
    "    # constructor method that init\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings  # Store the tokenized inputs (encodings) as a class attribute\n",
    "        self.labels = labels  # Store the labels (categories) as a class attribute\n",
    "\n",
    "    # method to get a single data sample\n",
    "    def __getitem__(self, idx):\n",
    "        # create a dictionary of tensors for each encoding key and the associated value at the index\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # add the label at index idx to the item dictionary\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    # method to return the total number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# create train and validation\n",
    "train_dataset = LegislativeDataset(train_encodings, train_labels)\n",
    "val_dataset = LegislativeDataset(val_encodings, val_labels)\n",
    "\n",
    "# load legal bert model for classification\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.to(device)\n",
    "\n",
    "# training arguments with wandb\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-6,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_grad_norm=1.0,\n",
    "    # Add wandb reporting\n",
    "    report_to=\"wandb\",\n",
    "    # Add run name for wandb\n",
    "    run_name=\"legal-bert-training\"\n",
    ")\n",
    "\n",
    "# trainer object for training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()\n",
    "\n",
    "# save fine tune model\n",
    "model.save_pretrained('./fine_tuned_legalbert')\n",
    "tokenizer.save_pretrained('./fine_tuned_legalbert')\n",
    "\n",
    "# evaluate model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# log final evaluation results to wandb\n",
    "wandb.log({\"final_evaluation\": eval_results})\n",
    "\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# close wanb\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4c3e2-83c5-4d91-a7f4-fbf3f020a3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
